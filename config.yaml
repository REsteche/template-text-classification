seed: 666
data_path: ./
train_batch_size: 32
eval_batch_size: 32
num_workers: 4
max_epochs: 20
train_epoch_length: 1000
eval_epoch_length: 1000
use_amp: false
debug: false
model: bert-base-uncased
model_dir: /tmp/model
tokenizer_dir: /tmp/tokenizer
num_classes: 1
drop_out: .3
n_fc: 768
weight_decay: 0.01
num_warmup_epochs: 0
max_length: 256
lr: 0.00005
filename_prefix: training
n_saved: 2
save_every_iters: 1000
patience: 6
output_dir: ./logs
log_every_iters: 2
